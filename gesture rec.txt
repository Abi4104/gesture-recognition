import cv2
import mediapipe as mp

# Initialize MediaPipe Hands and Drawing modules
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

# Set up webcam
cap = cv2.VideoCapture(0)

# Configure the Hands model
with mp_hands.Hands(
    max_num_hands=1,
    min_detection_confidence=0.7,
    min_tracking_confidence=0.5) as hands:

    while cap.isOpened():
        success, image = cap.read()
        if not success:
            print("Ignoring empty frame.")
            continue

        # Flip the image horizontally for natural viewing
        image = cv2.flip(image, 1)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = hands.process(image_rgb)

        gesture = "No Hand Detected"

        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)

                # Extract landmarks
                landmarks = hand_landmarks.landmark

                # Get required landmark positions
                thumb_tip = landmarks[mp_hands.HandLandmark.THUMB_TIP]
                thumb_ip = landmarks[mp_hands.HandLandmark.THUMB_IP]
                index_tip = landmarks[mp_hands.HandLandmark.INDEX_FINGER_TIP]
                middle_tip = landmarks[mp_hands.HandLandmark.MIDDLE_FINGER_TIP]
                ring_tip = landmarks[mp_hands.HandLandmark.RING_FINGER_TIP]
                pinky_tip = landmarks[mp_hands.HandLandmark.PINKY_TIP]
                wrist = landmarks[mp_hands.HandLandmark.WRIST]

                # Y-coordinates for comparison
                thumb_tip_y = thumb_tip.y
                thumb_ip_y = thumb_ip.y
                wrist_y = wrist.y
                index_y = index_tip.y
                middle_y = middle_tip.y
                ring_y = ring_tip.y
                pinky_y = pinky_tip.y

                # Gesture logic
                if (thumb_tip_y < wrist_y and
                    index_y > wrist_y and
                    middle_y > wrist_y and
                    ring_y > wrist_y and
                    pinky_y > wrist_y):
                    gesture = "Thumbs Up"

                elif (thumb_tip_y < wrist_y and index_y < wrist_y and middle_y < wrist_y and
                      ring_y < wrist_y and pinky_y < wrist_y):
                    gesture = "Open Palm"

                elif (thumb_tip_y > wrist_y and index_y > wrist_y and middle_y > wrist_y and
                      ring_y > wrist_y and pinky_y > wrist_y):
                    gesture = "Fist"

                else:
                    gesture = "Unknown Gesture"

        # Show gesture on screen
        cv2.putText(image, f'Gesture: {gesture}', (10, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        cv2.imshow('Gesture Recognition', image)

        if cv2.waitKey(5) & 0xFF == 27:  # ESC key
            break

cap.release()
cv2.destroyAllWindows()
